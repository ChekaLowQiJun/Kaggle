{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-12T10:15:37.445742Z","iopub.execute_input":"2023-08-12T10:15:37.446672Z","iopub.status.idle":"2023-08-12T10:15:37.462701Z","shell.execute_reply.started":"2023-08-12T10:15:37.446597Z","shell.execute_reply":"2023-08-12T10:15:37.460951Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_full = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\") #importing dataset and answers\ntest_full = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.464923Z","iopub.execute_input":"2023-08-12T10:15:37.465306Z","iopub.status.idle":"2023-08-12T10:15:37.516441Z","shell.execute_reply.started":"2023-08-12T10:15:37.465272Z","shell.execute_reply":"2023-08-12T10:15:37.515415Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"train_full.head() ","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.518658Z","iopub.execute_input":"2023-08-12T10:15:37.519342Z","iopub.status.idle":"2023-08-12T10:15:37.541965Z","shell.execute_reply.started":"2023-08-12T10:15:37.519309Z","shell.execute_reply":"2023-08-12T10:15:37.540555Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n\n   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n\n   Transported  \n0        False  \n1         True  \n2        False  \n3        False  \n4         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_full.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.546420Z","iopub.execute_input":"2023-08-12T10:15:37.546797Z","iopub.status.idle":"2023-08-12T10:15:37.572005Z","shell.execute_reply.started":"2023-08-12T10:15:37.546763Z","shell.execute_reply":"2023-08-12T10:15:37.571298Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8693 entries, 0 to 8692\nData columns (total 14 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   PassengerId   8693 non-null   object \n 1   HomePlanet    8492 non-null   object \n 2   CryoSleep     8476 non-null   object \n 3   Cabin         8494 non-null   object \n 4   Destination   8511 non-null   object \n 5   Age           8514 non-null   float64\n 6   VIP           8490 non-null   object \n 7   RoomService   8512 non-null   float64\n 8   FoodCourt     8510 non-null   float64\n 9   ShoppingMall  8485 non-null   float64\n 10  Spa           8510 non-null   float64\n 11  VRDeck        8505 non-null   float64\n 12  Name          8493 non-null   object \n 13  Transported   8693 non-null   bool   \ndtypes: bool(1), float64(6), object(7)\nmemory usage: 891.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train_full = train_full.drop('Transported' , axis = 1) \ny_train_full = train_full['Transported'].copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.574912Z","iopub.execute_input":"2023-08-12T10:15:37.575318Z","iopub.status.idle":"2023-08-12T10:15:37.582694Z","shell.execute_reply.started":"2023-08-12T10:15:37.575282Z","shell.execute_reply":"2023-08-12T10:15:37.581197Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nrandom_state = 28\nX_train, X_test, y_train,  y_test = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = random_state, stratify = y_train_full)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.583722Z","iopub.execute_input":"2023-08-12T10:15:37.584578Z","iopub.status.idle":"2023-08-12T10:15:37.604473Z","shell.execute_reply.started":"2023-08-12T10:15:37.584551Z","shell.execute_reply":"2023-08-12T10:15:37.602861Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = random_state, stratify = y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.605739Z","iopub.execute_input":"2023-08-12T10:15:37.606034Z","iopub.status.idle":"2023-08-12T10:15:37.615433Z","shell.execute_reply.started":"2023-08-12T10:15:37.606008Z","shell.execute_reply":"2023-08-12T10:15:37.614065Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"X_train_num = X_train.drop(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name'], axis = 1)\nX_val_num = X_val.drop(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name'], axis = 1)\nX_test_num = X_test.drop(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.616576Z","iopub.execute_input":"2023-08-12T10:15:37.616863Z","iopub.status.idle":"2023-08-12T10:15:37.628047Z","shell.execute_reply.started":"2023-08-12T10:15:37.616840Z","shell.execute_reply":"2023-08-12T10:15:37.627112Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"X_train_num.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.630510Z","iopub.execute_input":"2023-08-12T10:15:37.631013Z","iopub.status.idle":"2023-08-12T10:15:37.650789Z","shell.execute_reply.started":"2023-08-12T10:15:37.630981Z","shell.execute_reply":"2023-08-12T10:15:37.649752Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"       Age  RoomService  FoodCourt  ShoppingMall      Spa  VRDeck\n7308  24.0          0.0        0.0         809.0      0.0     0.0\n7401  25.0          0.0        0.0           0.0      0.0     0.0\n4677  24.0        530.0        0.0           0.0      0.0   179.0\n8459  27.0          0.0      984.0           0.0  13995.0   312.0\n5643  19.0        781.0        0.0         295.0    613.0     0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7308</th>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>809.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7401</th>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4677</th>\n      <td>24.0</td>\n      <td>530.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>8459</th>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>984.0</td>\n      <td>0.0</td>\n      <td>13995.0</td>\n      <td>312.0</td>\n    </tr>\n    <tr>\n      <th>5643</th>\n      <td>19.0</td>\n      <td>781.0</td>\n      <td>0.0</td>\n      <td>295.0</td>\n      <td>613.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline #Pipeline for Numerical features \nfrom sklearn.impute import SimpleImputer #Instantiate the Imputer \nfrom sklearn.preprocessing import StandardScaler #Instantiate Standard Scalar\nnum_pipeline = Pipeline([\n    ('imputer' , SimpleImputer(strategy='mean')) , \n    ('std_scaler' , StandardScaler()) , \n])","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.652506Z","iopub.execute_input":"2023-08-12T10:15:37.653871Z","iopub.status.idle":"2023-08-12T10:15:37.660405Z","shell.execute_reply.started":"2023-08-12T10:15:37.653821Z","shell.execute_reply":"2023-08-12T10:15:37.658036Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder #Instatitate OneHot\ncat_encoder = OneHotEncoder()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.662758Z","iopub.execute_input":"2023-08-12T10:15:37.663210Z","iopub.status.idle":"2023-08-12T10:15:37.675899Z","shell.execute_reply.started":"2023-08-12T10:15:37.663174Z","shell.execute_reply":"2023-08-12T10:15:37.674591Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer #Full pipeline for both Numerical and Categorical features\nX_train_num_attribs = list(X_train_num) \nX_train_cat_attribs = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\nfull_pipeline = ColumnTransformer([\n    ('num' , num_pipeline , X_train_num_attribs) , \n    ('cat' , OneHotEncoder() , X_train_cat_attribs) ,\n])\nfull_pipeline.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.677980Z","iopub.execute_input":"2023-08-12T10:15:37.678477Z","iopub.status.idle":"2023-08-12T10:15:37.722052Z","shell.execute_reply.started":"2023-08-12T10:15:37.678451Z","shell.execute_reply":"2023-08-12T10:15:37.721239Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"ColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer', SimpleImputer()),\n                                                 ('std_scaler',\n                                                  StandardScaler())]),\n                                 ['Age', 'RoomService', 'FoodCourt',\n                                  'ShoppingMall', 'Spa', 'VRDeck']),\n                                ('cat', OneHotEncoder(),\n                                 ['HomePlanet', 'CryoSleep', 'Destination',\n                                  'VIP'])])","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n                                                 (&#x27;std_scaler&#x27;,\n                                                  StandardScaler())]),\n                                 [&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n                                  &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]),\n                                (&#x27;cat&#x27;, OneHotEncoder(),\n                                 [&#x27;HomePlanet&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;,\n                                  &#x27;VIP&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n                                                 (&#x27;std_scaler&#x27;,\n                                                  StandardScaler())]),\n                                 [&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n                                  &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]),\n                                (&#x27;cat&#x27;, OneHotEncoder(),\n                                 [&#x27;HomePlanet&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;,\n                                  &#x27;VIP&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HomePlanet&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;VIP&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_prepared = full_pipeline.transform(X_train)\nX_val_prepared = full_pipeline.transform(X_val)\nX_test_prepared = full_pipeline.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.723020Z","iopub.execute_input":"2023-08-12T10:15:37.723284Z","iopub.status.idle":"2023-08-12T10:15:37.752965Z","shell.execute_reply.started":"2023-08-12T10:15:37.723262Z","shell.execute_reply":"2023-08-12T10:15:37.751669Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"X_train_prepared.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.755441Z","iopub.execute_input":"2023-08-12T10:15:37.756025Z","iopub.status.idle":"2023-08-12T10:15:37.763660Z","shell.execute_reply.started":"2023-08-12T10:15:37.755943Z","shell.execute_reply":"2023-08-12T10:15:37.762464Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(6954, 20)"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.764944Z","iopub.execute_input":"2023-08-12T10:15:37.766070Z","iopub.status.idle":"2023-08-12T10:15:37.801783Z","shell.execute_reply.started":"2023-08-12T10:15:37.766029Z","shell.execute_reply":"2023-08-12T10:15:37.800714Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_5 (Dense)             (None, 50)                1050      \n                                                                 \n dense_6 (Dense)             (None, 50)                2550      \n                                                                 \n alpha_dropout_2 (AlphaDropo  (None, 50)               0         \n ut)                                                             \n                                                                 \n dense_7 (Dense)             (None, 50)                2550      \n                                                                 \n alpha_dropout_3 (AlphaDropo  (None, 50)               0         \n ut)                                                             \n                                                                 \n dense_8 (Dense)             (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 6,201\nTrainable params: 6,201\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[20]):\n model = keras.models.Sequential()\n model.add(keras.layers.InputLayer(input_shape=input_shape))\n for layer in range(n_hidden):\n     model.add(keras.layers.Dense(n_neurons, activation=\"selu\",kernel_initializer='lecun_normal'))\n model.add(keras.layers.Dense(1, activation='sigmoid'))\n optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n return model","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.803034Z","iopub.execute_input":"2023-08-12T10:15:37.803345Z","iopub.status.idle":"2023-08-12T10:15:37.810205Z","shell.execute_reply.started":"2023-08-12T10:15:37.803321Z","shell.execute_reply":"2023-08-12T10:15:37.809199Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.811234Z","iopub.execute_input":"2023-08-12T10:15:37.811470Z","iopub.status.idle":"2023-08-12T10:15:37.821457Z","shell.execute_reply.started":"2023-08-12T10:15:37.811450Z","shell.execute_reply":"2023-08-12T10:15:37.820481Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1341954221.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n  keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import reciprocal\nfrom sklearn.model_selection import RandomizedSearchCV\nparam_distribs = {\n \"n_hidden\": [1, 2, 3, 4, 5],\n \"n_neurons\": [50, 100, 200, 300, 400, 500],\n \"learning_rate\": reciprocal(3e-4, 3e-2),\n}\nrnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=10, cv=3)\nrnd_search_cv.fit(X_train_prepared, y_train, epochs=30, validation_data=(X_val_prepared, y_val),callbacks=[keras.callbacks.EarlyStopping(patience=10)])","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:15:37.822245Z","iopub.execute_input":"2023-08-12T10:15:37.822478Z","iopub.status.idle":"2023-08-12T10:22:31.023163Z","shell.execute_reply.started":"2023-08-12T10:15:37.822459Z","shell.execute_reply":"2023-08-12T10:22:31.022229Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Epoch 1/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.5782 - accuracy: 0.7366 - val_loss: 0.4861 - val_accuracy: 0.7491\nEpoch 2/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7666 - val_loss: 0.4406 - val_accuracy: 0.7791\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4801 - accuracy: 0.7698 - val_loss: 0.4582 - val_accuracy: 0.7618\nEpoch 4/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4641 - accuracy: 0.7744 - val_loss: 0.4388 - val_accuracy: 0.7652\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4579 - accuracy: 0.7841 - val_loss: 0.4531 - val_accuracy: 0.7756\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.7770 - val_loss: 0.4620 - val_accuracy: 0.7791\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.7839 - val_loss: 0.4430 - val_accuracy: 0.7917\nEpoch 8/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4431 - accuracy: 0.7871 - val_loss: 0.4488 - val_accuracy: 0.7722\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4414 - accuracy: 0.7906 - val_loss: 0.4382 - val_accuracy: 0.7940\nEpoch 10/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4382 - accuracy: 0.7893 - val_loss: 0.4371 - val_accuracy: 0.7906\nEpoch 11/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4382 - accuracy: 0.7873 - val_loss: 0.4299 - val_accuracy: 0.7940\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4350 - accuracy: 0.7940 - val_loss: 0.4332 - val_accuracy: 0.7871\nEpoch 13/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.7949 - val_loss: 0.4294 - val_accuracy: 0.7860\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4349 - accuracy: 0.7983 - val_loss: 0.4413 - val_accuracy: 0.7906\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4307 - accuracy: 0.7987 - val_loss: 0.4301 - val_accuracy: 0.7883\nEpoch 16/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.7949 - val_loss: 0.4345 - val_accuracy: 0.7952\nEpoch 17/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.7966 - val_loss: 0.4295 - val_accuracy: 0.7883\nEpoch 18/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.7994 - val_loss: 0.4480 - val_accuracy: 0.7917\nEpoch 19/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.7953 - val_loss: 0.4372 - val_accuracy: 0.7837\nEpoch 20/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4289 - accuracy: 0.7987 - val_loss: 0.4415 - val_accuracy: 0.7710\nEpoch 21/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.7949 - val_loss: 0.4298 - val_accuracy: 0.7860\nEpoch 22/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.8000 - val_loss: 0.4253 - val_accuracy: 0.7894\nEpoch 23/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4241 - accuracy: 0.7944 - val_loss: 0.4360 - val_accuracy: 0.7825\nEpoch 24/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.7985 - val_loss: 0.4513 - val_accuracy: 0.7871\nEpoch 25/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.7977 - val_loss: 0.4725 - val_accuracy: 0.7802\nEpoch 26/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8028 - val_loss: 0.4285 - val_accuracy: 0.7940\nEpoch 27/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.8000 - val_loss: 0.4346 - val_accuracy: 0.7871\nEpoch 28/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4198 - accuracy: 0.8000 - val_loss: 0.4338 - val_accuracy: 0.7860\nEpoch 29/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.8009 - val_loss: 0.4352 - val_accuracy: 0.7940\nEpoch 30/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.7990 - val_loss: 0.4398 - val_accuracy: 0.7848\n73/73 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7955\nEpoch 1/30\n145/145 [==============================] - 2s 5ms/step - loss: 0.5893 - accuracy: 0.7425 - val_loss: 0.5078 - val_accuracy: 0.7652\nEpoch 2/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4902 - accuracy: 0.7714 - val_loss: 0.4673 - val_accuracy: 0.7791\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4693 - accuracy: 0.7798 - val_loss: 0.4844 - val_accuracy: 0.7606\nEpoch 4/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4620 - accuracy: 0.7750 - val_loss: 0.4954 - val_accuracy: 0.7215\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4568 - val_accuracy: 0.7917\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4449 - accuracy: 0.7908 - val_loss: 0.4285 - val_accuracy: 0.7963\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.4228 - val_accuracy: 0.7975\nEpoch 8/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.7886 - val_loss: 0.4312 - val_accuracy: 0.7906\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.7944 - val_loss: 0.4267 - val_accuracy: 0.7894\nEpoch 10/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.7908 - val_loss: 0.4396 - val_accuracy: 0.8021\nEpoch 11/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.4256 - val_accuracy: 0.7906\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.7955 - val_loss: 0.4492 - val_accuracy: 0.7756\nEpoch 13/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4241 - accuracy: 0.7970 - val_loss: 0.4446 - val_accuracy: 0.7860\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.8024 - val_loss: 0.4382 - val_accuracy: 0.7848\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4197 - accuracy: 0.7998 - val_loss: 0.4435 - val_accuracy: 0.7940\nEpoch 16/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4191 - accuracy: 0.8009 - val_loss: 0.4411 - val_accuracy: 0.7917\nEpoch 17/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4167 - accuracy: 0.7957 - val_loss: 0.4351 - val_accuracy: 0.7894\n73/73 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7830\nEpoch 1/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.5826 - accuracy: 0.7409 - val_loss: 0.4589 - val_accuracy: 0.7952\nEpoch 2/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4915 - accuracy: 0.7614 - val_loss: 0.4818 - val_accuracy: 0.7560\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4726 - accuracy: 0.7729 - val_loss: 0.5259 - val_accuracy: 0.7411\nEpoch 4/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4595 - accuracy: 0.7744 - val_loss: 0.4773 - val_accuracy: 0.7791\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.7791 - val_loss: 0.4617 - val_accuracy: 0.7883\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4449 - accuracy: 0.7843 - val_loss: 0.4374 - val_accuracy: 0.8044\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4644 - val_accuracy: 0.7779\nEpoch 8/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.7877 - val_loss: 0.4635 - val_accuracy: 0.7883\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.7901 - val_loss: 0.4613 - val_accuracy: 0.7745\nEpoch 10/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.7938 - val_loss: 0.4448 - val_accuracy: 0.7837\nEpoch 11/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.7955 - val_loss: 0.4406 - val_accuracy: 0.7940\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4246 - accuracy: 0.7944 - val_loss: 0.4340 - val_accuracy: 0.7963\nEpoch 13/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4215 - accuracy: 0.7992 - val_loss: 0.4290 - val_accuracy: 0.7963\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4202 - accuracy: 0.7975 - val_loss: 0.4409 - val_accuracy: 0.7871\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4204 - accuracy: 0.8024 - val_loss: 0.4454 - val_accuracy: 0.7883\nEpoch 16/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.7959 - val_loss: 0.4419 - val_accuracy: 0.7871\nEpoch 17/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4172 - accuracy: 0.7975 - val_loss: 0.4281 - val_accuracy: 0.7825\nEpoch 18/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4164 - accuracy: 0.7987 - val_loss: 0.4333 - val_accuracy: 0.7871\nEpoch 19/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4149 - accuracy: 0.7992 - val_loss: 0.4448 - val_accuracy: 0.7883\nEpoch 20/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8009 - val_loss: 0.4569 - val_accuracy: 0.7745\nEpoch 21/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.7949 - val_loss: 0.4573 - val_accuracy: 0.7779\nEpoch 22/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.8013 - val_loss: 0.4326 - val_accuracy: 0.7860\nEpoch 23/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.8061 - val_loss: 0.4447 - val_accuracy: 0.7722\nEpoch 24/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8057 - val_loss: 0.4516 - val_accuracy: 0.7894\nEpoch 25/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8041 - val_loss: 0.4573 - val_accuracy: 0.7560\nEpoch 26/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4097 - accuracy: 0.7996 - val_loss: 0.4473 - val_accuracy: 0.7883\nEpoch 27/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4057 - accuracy: 0.8063 - val_loss: 0.4457 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7908\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7686 - val_loss: 0.4419 - val_accuracy: 0.7894\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7819 - val_loss: 0.4459 - val_accuracy: 0.7883\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7811 - val_loss: 0.4656 - val_accuracy: 0.7917\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7875 - val_loss: 0.4470 - val_accuracy: 0.7940\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4441 - val_accuracy: 0.7779\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7860 - val_loss: 0.4397 - val_accuracy: 0.7871\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7880 - val_loss: 0.4426 - val_accuracy: 0.7917\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4405 - val_accuracy: 0.7871\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7862 - val_loss: 0.4496 - val_accuracy: 0.8021\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7987 - val_loss: 0.4443 - val_accuracy: 0.7940\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7914 - val_loss: 0.4336 - val_accuracy: 0.7963\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7903 - val_loss: 0.4409 - val_accuracy: 0.7963\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7936 - val_loss: 0.4362 - val_accuracy: 0.8009\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7890 - val_loss: 0.4779 - val_accuracy: 0.7537\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7895 - val_loss: 0.4280 - val_accuracy: 0.7917\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4273 - val_accuracy: 0.7975\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7918 - val_loss: 0.4341 - val_accuracy: 0.7952\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7910 - val_loss: 0.4343 - val_accuracy: 0.7940\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7918 - val_loss: 0.4343 - val_accuracy: 0.7929\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7910 - val_loss: 0.4363 - val_accuracy: 0.7975\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7875 - val_loss: 0.4472 - val_accuracy: 0.7871\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7929 - val_loss: 0.4304 - val_accuracy: 0.7940\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7947 - val_loss: 0.4308 - val_accuracy: 0.7940\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7890 - val_loss: 0.4348 - val_accuracy: 0.7963\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7936 - val_loss: 0.4372 - val_accuracy: 0.7998\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7916 - val_loss: 0.4420 - val_accuracy: 0.7894\n73/73 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7718\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.7677 - val_loss: 0.4739 - val_accuracy: 0.7745\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7821 - val_loss: 0.4516 - val_accuracy: 0.7837\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7875 - val_loss: 0.4432 - val_accuracy: 0.7917\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7908 - val_loss: 0.4344 - val_accuracy: 0.7871\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7897 - val_loss: 0.4360 - val_accuracy: 0.7848\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7880 - val_loss: 0.4421 - val_accuracy: 0.7986\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7895 - val_loss: 0.4443 - val_accuracy: 0.7860\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7923 - val_loss: 0.4419 - val_accuracy: 0.7791\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7895 - val_loss: 0.4377 - val_accuracy: 0.7883\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7537\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7916 - val_loss: 0.4296 - val_accuracy: 0.7894\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7929 - val_loss: 0.4473 - val_accuracy: 0.7986\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7940 - val_loss: 0.4508 - val_accuracy: 0.7791\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7942 - val_loss: 0.4300 - val_accuracy: 0.7998\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.4425 - val_accuracy: 0.7756\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7912 - val_loss: 0.4371 - val_accuracy: 0.7986\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7927 - val_loss: 0.4444 - val_accuracy: 0.7929\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7910 - val_loss: 0.4363 - val_accuracy: 0.7837\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7994 - val_loss: 0.4416 - val_accuracy: 0.7802\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7938 - val_loss: 0.4394 - val_accuracy: 0.7848\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7895 - val_loss: 0.4362 - val_accuracy: 0.8021\n73/73 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7925\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4753 - accuracy: 0.7647 - val_loss: 0.4433 - val_accuracy: 0.7906\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7845 - val_loss: 0.4599 - val_accuracy: 0.7699\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7869 - val_loss: 0.4361 - val_accuracy: 0.7825\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7841 - val_loss: 0.4458 - val_accuracy: 0.7871\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7880 - val_loss: 0.4311 - val_accuracy: 0.7837\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7903 - val_loss: 0.4355 - val_accuracy: 0.7906\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7854 - val_loss: 0.4374 - val_accuracy: 0.7952\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7955 - val_loss: 0.4481 - val_accuracy: 0.7917\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7925 - val_loss: 0.4368 - val_accuracy: 0.7929\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7895 - val_loss: 0.4335 - val_accuracy: 0.7894\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7931 - val_loss: 0.4332 - val_accuracy: 0.7883\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7936 - val_loss: 0.4717 - val_accuracy: 0.7572\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7897 - val_loss: 0.4379 - val_accuracy: 0.7848\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7925 - val_loss: 0.4355 - val_accuracy: 0.7906\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7910 - val_loss: 0.4341 - val_accuracy: 0.7883\n73/73 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7908\nEpoch 1/30\n145/145 [==============================] - 2s 7ms/step - loss: 0.7312 - accuracy: 0.7271 - val_loss: 0.7729 - val_accuracy: 0.6410\nEpoch 2/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.5405 - accuracy: 0.7474 - val_loss: 0.6980 - val_accuracy: 0.7089\nEpoch 3/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4935 - accuracy: 0.7681 - val_loss: 0.4461 - val_accuracy: 0.7848\nEpoch 4/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7694 - val_loss: 0.4312 - val_accuracy: 0.7998\nEpoch 5/30\n145/145 [==============================] - 1s 7ms/step - loss: 0.4567 - accuracy: 0.7817 - val_loss: 0.4347 - val_accuracy: 0.7906\nEpoch 6/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4483 - accuracy: 0.7886 - val_loss: 0.4421 - val_accuracy: 0.7837\nEpoch 7/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4345 - val_accuracy: 0.7883\nEpoch 8/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4398 - accuracy: 0.7901 - val_loss: 0.4284 - val_accuracy: 0.7837\nEpoch 9/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4403 - accuracy: 0.7912 - val_loss: 0.4412 - val_accuracy: 0.7722\nEpoch 10/30\n145/145 [==============================] - 1s 7ms/step - loss: 0.4412 - accuracy: 0.7916 - val_loss: 0.4363 - val_accuracy: 0.7883\nEpoch 11/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4386 - accuracy: 0.7929 - val_loss: 0.4372 - val_accuracy: 0.7906\nEpoch 12/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4364 - accuracy: 0.7916 - val_loss: 0.4437 - val_accuracy: 0.7871\nEpoch 13/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4348 - accuracy: 0.7910 - val_loss: 0.4312 - val_accuracy: 0.7906\nEpoch 14/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4322 - accuracy: 0.7949 - val_loss: 0.4366 - val_accuracy: 0.7917\nEpoch 15/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4316 - accuracy: 0.7949 - val_loss: 0.4395 - val_accuracy: 0.7814\nEpoch 16/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4431 - val_accuracy: 0.7802\nEpoch 17/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4309 - accuracy: 0.7972 - val_loss: 0.4377 - val_accuracy: 0.7837\nEpoch 18/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4317 - accuracy: 0.7966 - val_loss: 0.4336 - val_accuracy: 0.7871\n73/73 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8007\nEpoch 1/30\n145/145 [==============================] - 2s 7ms/step - loss: 0.7768 - accuracy: 0.7140 - val_loss: 0.5378 - val_accuracy: 0.7641\nEpoch 2/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7571 - val_loss: 0.5699 - val_accuracy: 0.7054\nEpoch 3/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7664 - val_loss: 0.4420 - val_accuracy: 0.7952\nEpoch 4/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7759 - val_loss: 0.4561 - val_accuracy: 0.7848\nEpoch 5/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4464 - accuracy: 0.7888 - val_loss: 0.4502 - val_accuracy: 0.7894\nEpoch 6/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4330 - val_accuracy: 0.7998\nEpoch 7/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4376 - accuracy: 0.7942 - val_loss: 0.4309 - val_accuracy: 0.7860\nEpoch 8/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4366 - accuracy: 0.7906 - val_loss: 0.4418 - val_accuracy: 0.7883\nEpoch 9/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4328 - accuracy: 0.7918 - val_loss: 0.4332 - val_accuracy: 0.8032\nEpoch 10/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4311 - accuracy: 0.7942 - val_loss: 0.4339 - val_accuracy: 0.7883\nEpoch 11/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.7942 - val_loss: 0.4378 - val_accuracy: 0.7860\nEpoch 12/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.7962 - val_loss: 0.4219 - val_accuracy: 0.7929\nEpoch 13/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.7996 - val_loss: 0.4370 - val_accuracy: 0.8009\nEpoch 14/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.7968 - val_loss: 0.4260 - val_accuracy: 0.7883\nEpoch 15/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.7959 - val_loss: 0.4275 - val_accuracy: 0.8032\nEpoch 16/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8000 - val_loss: 0.4397 - val_accuracy: 0.7699\nEpoch 17/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8011 - val_loss: 0.4387 - val_accuracy: 0.7975\nEpoch 18/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.7998 - val_loss: 0.4329 - val_accuracy: 0.7779\nEpoch 19/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.7972 - val_loss: 0.4594 - val_accuracy: 0.7791\nEpoch 20/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4198 - accuracy: 0.8046 - val_loss: 0.4331 - val_accuracy: 0.7963\nEpoch 21/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.4249 - val_accuracy: 0.7894\nEpoch 22/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4144 - accuracy: 0.8011 - val_loss: 0.4307 - val_accuracy: 0.7963\n73/73 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7847\nEpoch 1/30\n145/145 [==============================] - 2s 7ms/step - loss: 0.7584 - accuracy: 0.7224 - val_loss: 0.5650 - val_accuracy: 0.7560\nEpoch 2/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.5318 - accuracy: 0.7554 - val_loss: 0.5276 - val_accuracy: 0.7250\nEpoch 3/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4834 - accuracy: 0.7683 - val_loss: 0.5125 - val_accuracy: 0.7388\nEpoch 4/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4601 - accuracy: 0.7800 - val_loss: 0.5193 - val_accuracy: 0.7906\nEpoch 5/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4485 - accuracy: 0.7854 - val_loss: 0.4491 - val_accuracy: 0.7675\nEpoch 6/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4403 - accuracy: 0.7839 - val_loss: 0.4562 - val_accuracy: 0.7814\nEpoch 7/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4369 - accuracy: 0.7886 - val_loss: 0.4433 - val_accuracy: 0.7514\nEpoch 8/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.7977 - val_loss: 0.4337 - val_accuracy: 0.7894\nEpoch 9/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.7929 - val_loss: 0.4678 - val_accuracy: 0.7768\nEpoch 10/30\n145/145 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.7940 - val_loss: 0.4412 - val_accuracy: 0.7871\nEpoch 11/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4245 - accuracy: 0.7949 - val_loss: 0.4655 - val_accuracy: 0.7791\nEpoch 12/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4228 - accuracy: 0.7981 - val_loss: 0.4381 - val_accuracy: 0.7860\nEpoch 13/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.7987 - val_loss: 0.4412 - val_accuracy: 0.7906\nEpoch 14/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.7962 - val_loss: 0.4467 - val_accuracy: 0.7848\nEpoch 15/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.7972 - val_loss: 0.4479 - val_accuracy: 0.7906\nEpoch 16/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8007 - val_loss: 0.4618 - val_accuracy: 0.7802\nEpoch 17/30\n145/145 [==============================] - 1s 6ms/step - loss: 0.4167 - accuracy: 0.7962 - val_loss: 0.4599 - val_accuracy: 0.7848\nEpoch 18/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8013 - val_loss: 0.4384 - val_accuracy: 0.7952\n73/73 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7912\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4762 - accuracy: 0.7655 - val_loss: 0.4434 - val_accuracy: 0.7894\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7802 - val_loss: 0.4509 - val_accuracy: 0.7860\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7852 - val_loss: 0.4767 - val_accuracy: 0.7699\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7856 - val_loss: 0.4417 - val_accuracy: 0.7952\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7854 - val_loss: 0.4422 - val_accuracy: 0.7975\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7854 - val_loss: 0.4433 - val_accuracy: 0.7894\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7800 - val_loss: 0.4395 - val_accuracy: 0.7952\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7906 - val_loss: 0.4353 - val_accuracy: 0.7894\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7877 - val_loss: 0.4355 - val_accuracy: 0.7940\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7936 - val_loss: 0.4403 - val_accuracy: 0.7814\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7860 - val_loss: 0.4602 - val_accuracy: 0.7606\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.4299 - val_accuracy: 0.7871\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7914 - val_loss: 0.4418 - val_accuracy: 0.7998\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4344 - val_accuracy: 0.7929\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7867 - val_loss: 0.4327 - val_accuracy: 0.7883\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7836 - val_loss: 0.4412 - val_accuracy: 0.8021\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7871 - val_loss: 0.4438 - val_accuracy: 0.7802\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7916 - val_loss: 0.4441 - val_accuracy: 0.7883\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7908 - val_loss: 0.4466 - val_accuracy: 0.7779\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7873 - val_loss: 0.4308 - val_accuracy: 0.7929\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7910 - val_loss: 0.4454 - val_accuracy: 0.7618\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7888 - val_loss: 0.4420 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7895\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4752 - accuracy: 0.7657 - val_loss: 0.4379 - val_accuracy: 0.7929\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7877 - val_loss: 0.4495 - val_accuracy: 0.7871\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.4569 - val_accuracy: 0.7883\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7877 - val_loss: 0.4428 - val_accuracy: 0.7906\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7871 - val_loss: 0.4409 - val_accuracy: 0.7860\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7910 - val_loss: 0.4352 - val_accuracy: 0.7779\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.4376 - val_accuracy: 0.7929\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7906 - val_loss: 0.4404 - val_accuracy: 0.7860\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7918 - val_loss: 0.4372 - val_accuracy: 0.7998\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7908 - val_loss: 0.4343 - val_accuracy: 0.7883\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.4470 - val_accuracy: 0.7963\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7942 - val_loss: 0.4331 - val_accuracy: 0.7998\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7888 - val_loss: 0.4395 - val_accuracy: 0.7975\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7912 - val_loss: 0.4405 - val_accuracy: 0.7848\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7925 - val_loss: 0.4446 - val_accuracy: 0.7975\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7968 - val_loss: 0.4402 - val_accuracy: 0.7963\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7942 - val_loss: 0.4380 - val_accuracy: 0.8009\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7927 - val_loss: 0.4344 - val_accuracy: 0.7940\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7942 - val_loss: 0.4344 - val_accuracy: 0.7952\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7940 - val_loss: 0.4394 - val_accuracy: 0.7917\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7944 - val_loss: 0.4377 - val_accuracy: 0.7975\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7981 - val_loss: 0.4442 - val_accuracy: 0.7860\n73/73 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7718\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.7783 - val_loss: 0.4402 - val_accuracy: 0.7894\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7852 - val_loss: 0.4676 - val_accuracy: 0.7756\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7826 - val_loss: 0.4593 - val_accuracy: 0.7802\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7875 - val_loss: 0.4394 - val_accuracy: 0.7906\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7811 - val_loss: 0.4362 - val_accuracy: 0.7860\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7908 - val_loss: 0.4382 - val_accuracy: 0.7952\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.4393 - val_accuracy: 0.7975\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7877 - val_loss: 0.4389 - val_accuracy: 0.7860\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7914 - val_loss: 0.4329 - val_accuracy: 0.7871\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7914 - val_loss: 0.4483 - val_accuracy: 0.7917\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7912 - val_loss: 0.4387 - val_accuracy: 0.7860\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7918 - val_loss: 0.4487 - val_accuracy: 0.7894\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7912 - val_loss: 0.4371 - val_accuracy: 0.7906\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7944 - val_loss: 0.4346 - val_accuracy: 0.7917\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7916 - val_loss: 0.4408 - val_accuracy: 0.7929\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7975 - val_loss: 0.4309 - val_accuracy: 0.7917\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7884 - val_loss: 0.4389 - val_accuracy: 0.7940\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7979 - val_loss: 0.4528 - val_accuracy: 0.7906\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7979 - val_loss: 0.4382 - val_accuracy: 0.7940\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.4430 - val_accuracy: 0.7883\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7912 - val_loss: 0.4269 - val_accuracy: 0.7975\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7910 - val_loss: 0.4491 - val_accuracy: 0.7871\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7966 - val_loss: 0.4300 - val_accuracy: 0.7906\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7910 - val_loss: 0.4324 - val_accuracy: 0.7871\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7968 - val_loss: 0.4366 - val_accuracy: 0.7883\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7903 - val_loss: 0.4344 - val_accuracy: 0.7871\nEpoch 27/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7942 - val_loss: 0.4365 - val_accuracy: 0.7963\nEpoch 28/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7992 - val_loss: 0.4366 - val_accuracy: 0.7825\nEpoch 29/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8009 - val_loss: 0.4279 - val_accuracy: 0.7848\nEpoch 30/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7916 - val_loss: 0.4313 - val_accuracy: 0.7986\n73/73 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7877\nEpoch 1/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.6182 - accuracy: 0.7381 - val_loss: 0.5443 - val_accuracy: 0.7376\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7629 - val_loss: 0.5093 - val_accuracy: 0.7388\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4700 - accuracy: 0.7763 - val_loss: 0.4572 - val_accuracy: 0.7710\nEpoch 4/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7804 - val_loss: 0.4605 - val_accuracy: 0.7871\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4497 - accuracy: 0.7852 - val_loss: 0.4370 - val_accuracy: 0.7998\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.7877 - val_loss: 0.4587 - val_accuracy: 0.7664\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4509 - val_accuracy: 0.7929\nEpoch 8/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.7893 - val_loss: 0.4385 - val_accuracy: 0.7802\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.7914 - val_loss: 0.4396 - val_accuracy: 0.7814\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7934 - val_loss: 0.4265 - val_accuracy: 0.7917\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7912 - val_loss: 0.4312 - val_accuracy: 0.7825\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.7936 - val_loss: 0.4338 - val_accuracy: 0.7906\nEpoch 13/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.7918 - val_loss: 0.4368 - val_accuracy: 0.7837\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4280 - accuracy: 0.7929 - val_loss: 0.4563 - val_accuracy: 0.7768\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4276 - accuracy: 0.7916 - val_loss: 0.4344 - val_accuracy: 0.7906\nEpoch 16/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8007 - val_loss: 0.4603 - val_accuracy: 0.7664\nEpoch 17/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.7964 - val_loss: 0.4229 - val_accuracy: 0.7929\nEpoch 18/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4246 - accuracy: 0.7979 - val_loss: 0.4380 - val_accuracy: 0.7906\nEpoch 19/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4233 - accuracy: 0.7918 - val_loss: 0.4296 - val_accuracy: 0.7894\nEpoch 20/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7968 - val_loss: 0.4514 - val_accuracy: 0.7733\nEpoch 21/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4216 - accuracy: 0.7983 - val_loss: 0.4373 - val_accuracy: 0.7871\nEpoch 22/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4216 - accuracy: 0.7955 - val_loss: 0.4416 - val_accuracy: 0.7860\nEpoch 23/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7968 - val_loss: 0.4357 - val_accuracy: 0.7848\nEpoch 24/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8011 - val_loss: 0.4328 - val_accuracy: 0.7860\nEpoch 25/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8013 - val_loss: 0.4433 - val_accuracy: 0.7871\nEpoch 26/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4184 - accuracy: 0.8000 - val_loss: 0.4562 - val_accuracy: 0.7710\nEpoch 27/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.7992 - val_loss: 0.4370 - val_accuracy: 0.7825\n73/73 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.7990\nEpoch 1/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.6427 - accuracy: 0.7371 - val_loss: 0.4522 - val_accuracy: 0.7906\nEpoch 2/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7651 - val_loss: 0.4582 - val_accuracy: 0.7940\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.7783 - val_loss: 0.4346 - val_accuracy: 0.7952\nEpoch 4/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4462 - accuracy: 0.7819 - val_loss: 0.4567 - val_accuracy: 0.7675\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4420 - accuracy: 0.7841 - val_loss: 0.4353 - val_accuracy: 0.7975\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.7867 - val_loss: 0.4333 - val_accuracy: 0.8032\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4319 - accuracy: 0.7931 - val_loss: 0.4497 - val_accuracy: 0.7940\nEpoch 8/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.7953 - val_loss: 0.4276 - val_accuracy: 0.7883\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.7977 - val_loss: 0.4237 - val_accuracy: 0.7998\nEpoch 10/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4236 - accuracy: 0.7975 - val_loss: 0.4289 - val_accuracy: 0.7929\nEpoch 11/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4221 - accuracy: 0.7929 - val_loss: 0.4260 - val_accuracy: 0.7975\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4210 - accuracy: 0.7949 - val_loss: 0.4424 - val_accuracy: 0.7986\nEpoch 13/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.7983 - val_loss: 0.4313 - val_accuracy: 0.7952\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4157 - accuracy: 0.7977 - val_loss: 0.4433 - val_accuracy: 0.7871\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.4385 - val_accuracy: 0.7917\nEpoch 16/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4146 - accuracy: 0.8016 - val_loss: 0.4359 - val_accuracy: 0.7952\nEpoch 17/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4157 - accuracy: 0.7990 - val_loss: 0.4289 - val_accuracy: 0.7906\nEpoch 18/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4146 - accuracy: 0.8031 - val_loss: 0.4296 - val_accuracy: 0.7906\nEpoch 19/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8009 - val_loss: 0.4309 - val_accuracy: 0.7952\n73/73 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7860\nEpoch 1/30\n145/145 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.7388 - val_loss: 0.5613 - val_accuracy: 0.7722\nEpoch 2/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.7692 - val_loss: 0.4557 - val_accuracy: 0.7802\nEpoch 3/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.7808 - val_loss: 0.4355 - val_accuracy: 0.7998\nEpoch 4/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4434 - accuracy: 0.7839 - val_loss: 0.4252 - val_accuracy: 0.7894\nEpoch 5/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.7893 - val_loss: 0.4327 - val_accuracy: 0.7848\nEpoch 6/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.7944 - val_loss: 0.4249 - val_accuracy: 0.7929\nEpoch 7/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.4365 - val_accuracy: 0.7906\nEpoch 8/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.7957 - val_loss: 0.4651 - val_accuracy: 0.7618\nEpoch 9/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4234 - accuracy: 0.7966 - val_loss: 0.4701 - val_accuracy: 0.7595\nEpoch 10/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.7923 - val_loss: 0.4292 - val_accuracy: 0.7940\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.4410 - val_accuracy: 0.7722\nEpoch 12/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4191 - accuracy: 0.7979 - val_loss: 0.4435 - val_accuracy: 0.7917\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7985 - val_loss: 0.4266 - val_accuracy: 0.7986\nEpoch 14/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4198 - accuracy: 0.7940 - val_loss: 0.4450 - val_accuracy: 0.7963\nEpoch 15/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4175 - accuracy: 0.7977 - val_loss: 0.4316 - val_accuracy: 0.7825\nEpoch 16/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4161 - accuracy: 0.8009 - val_loss: 0.4452 - val_accuracy: 0.7860\n73/73 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7735\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.7709 - val_loss: 0.4422 - val_accuracy: 0.7768\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7858 - val_loss: 0.4363 - val_accuracy: 0.7848\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7877 - val_loss: 0.4383 - val_accuracy: 0.7929\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7901 - val_loss: 0.4391 - val_accuracy: 0.7917\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7912 - val_loss: 0.4285 - val_accuracy: 0.7894\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7916 - val_loss: 0.4320 - val_accuracy: 0.7894\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7888 - val_loss: 0.4342 - val_accuracy: 0.7894\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7938 - val_loss: 0.4298 - val_accuracy: 0.7917\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7947 - val_loss: 0.4272 - val_accuracy: 0.7894\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7921 - val_loss: 0.4345 - val_accuracy: 0.7986\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7942 - val_loss: 0.4372 - val_accuracy: 0.7917\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7949 - val_loss: 0.4380 - val_accuracy: 0.7917\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7940 - val_loss: 0.4275 - val_accuracy: 0.7848\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7929 - val_loss: 0.4287 - val_accuracy: 0.7894\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7962 - val_loss: 0.4293 - val_accuracy: 0.7975\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7931 - val_loss: 0.4244 - val_accuracy: 0.7917\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7938 - val_loss: 0.4208 - val_accuracy: 0.7917\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7957 - val_loss: 0.4433 - val_accuracy: 0.7848\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7944 - val_loss: 0.4238 - val_accuracy: 0.7860\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7947 - val_loss: 0.4283 - val_accuracy: 0.7848\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8000 - val_loss: 0.4279 - val_accuracy: 0.7860\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7947 - val_loss: 0.4350 - val_accuracy: 0.7825\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7992 - val_loss: 0.4377 - val_accuracy: 0.7779\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7987 - val_loss: 0.4485 - val_accuracy: 0.7791\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7966 - val_loss: 0.4375 - val_accuracy: 0.7825\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7983 - val_loss: 0.4319 - val_accuracy: 0.7848\nEpoch 27/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8013 - val_loss: 0.4231 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.7985\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4747 - accuracy: 0.7716 - val_loss: 0.4469 - val_accuracy: 0.7848\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7860 - val_loss: 0.4423 - val_accuracy: 0.7998\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7908 - val_loss: 0.4317 - val_accuracy: 0.7883\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7916 - val_loss: 0.4302 - val_accuracy: 0.7917\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7897 - val_loss: 0.4404 - val_accuracy: 0.7975\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7955 - val_loss: 0.4256 - val_accuracy: 0.7894\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.4266 - val_accuracy: 0.7986\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7944 - val_loss: 0.4298 - val_accuracy: 0.7986\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7983 - val_loss: 0.4366 - val_accuracy: 0.7860\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7953 - val_loss: 0.4299 - val_accuracy: 0.7998\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7964 - val_loss: 0.4321 - val_accuracy: 0.7883\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7955 - val_loss: 0.4453 - val_accuracy: 0.7963\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7975 - val_loss: 0.4358 - val_accuracy: 0.7963\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7966 - val_loss: 0.4349 - val_accuracy: 0.7860\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7970 - val_loss: 0.4377 - val_accuracy: 0.7986\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8020 - val_loss: 0.4339 - val_accuracy: 0.7837\n73/73 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7666\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.7739 - val_loss: 0.4523 - val_accuracy: 0.7825\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7862 - val_loss: 0.4343 - val_accuracy: 0.7883\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.4438 - val_accuracy: 0.7963\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7886 - val_loss: 0.4359 - val_accuracy: 0.7837\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7949 - val_loss: 0.4444 - val_accuracy: 0.7883\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7903 - val_loss: 0.4363 - val_accuracy: 0.7894\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7964 - val_loss: 0.4321 - val_accuracy: 0.7906\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4314 - val_accuracy: 0.7894\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7979 - val_loss: 0.4297 - val_accuracy: 0.7906\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7931 - val_loss: 0.4347 - val_accuracy: 0.7825\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7970 - val_loss: 0.4289 - val_accuracy: 0.7871\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7990 - val_loss: 0.4392 - val_accuracy: 0.7883\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7987 - val_loss: 0.4299 - val_accuracy: 0.7906\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8009 - val_loss: 0.4385 - val_accuracy: 0.7883\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7996 - val_loss: 0.4383 - val_accuracy: 0.7848\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.4272 - val_accuracy: 0.7871\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8005 - val_loss: 0.4367 - val_accuracy: 0.7894\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7977 - val_loss: 0.4338 - val_accuracy: 0.7768\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7949 - val_loss: 0.4269 - val_accuracy: 0.7883\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7985 - val_loss: 0.4312 - val_accuracy: 0.7791\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8022 - val_loss: 0.4387 - val_accuracy: 0.7825\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7990 - val_loss: 0.4359 - val_accuracy: 0.7848\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8013 - val_loss: 0.4383 - val_accuracy: 0.7699\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8003 - val_loss: 0.4423 - val_accuracy: 0.7756\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8028 - val_loss: 0.4331 - val_accuracy: 0.7745\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7972 - val_loss: 0.4408 - val_accuracy: 0.7837\nEpoch 27/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8009 - val_loss: 0.4367 - val_accuracy: 0.7883\nEpoch 28/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7985 - val_loss: 0.4301 - val_accuracy: 0.7906\nEpoch 29/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8020 - val_loss: 0.4363 - val_accuracy: 0.7883\n73/73 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7947\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.7707 - val_loss: 0.4414 - val_accuracy: 0.7986\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7886 - val_loss: 0.4370 - val_accuracy: 0.7791\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7860 - val_loss: 0.4378 - val_accuracy: 0.7848\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7873 - val_loss: 0.4383 - val_accuracy: 0.7906\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7858 - val_loss: 0.4510 - val_accuracy: 0.7825\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7871 - val_loss: 0.4668 - val_accuracy: 0.7791\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7910 - val_loss: 0.4376 - val_accuracy: 0.7883\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7856 - val_loss: 0.4386 - val_accuracy: 0.7894\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7873 - val_loss: 0.4400 - val_accuracy: 0.7986\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7867 - val_loss: 0.4426 - val_accuracy: 0.7883\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7901 - val_loss: 0.4389 - val_accuracy: 0.7917\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7858 - val_loss: 0.4427 - val_accuracy: 0.7883\n73/73 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7908\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4461 - val_accuracy: 0.7860\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4622 - val_accuracy: 0.7756\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7910 - val_loss: 0.4468 - val_accuracy: 0.7917\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7897 - val_loss: 0.4447 - val_accuracy: 0.7883\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7940 - val_loss: 0.4402 - val_accuracy: 0.7894\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7886 - val_loss: 0.4381 - val_accuracy: 0.7917\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7927 - val_loss: 0.4370 - val_accuracy: 0.7975\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7942 - val_loss: 0.4382 - val_accuracy: 0.7929\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.4558 - val_accuracy: 0.7837\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7970 - val_loss: 0.4334 - val_accuracy: 0.7940\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7925 - val_loss: 0.4526 - val_accuracy: 0.7929\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7925 - val_loss: 0.4304 - val_accuracy: 0.7894\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7925 - val_loss: 0.4383 - val_accuracy: 0.7906\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7936 - val_loss: 0.4432 - val_accuracy: 0.7779\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7972 - val_loss: 0.4362 - val_accuracy: 0.7975\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7923 - val_loss: 0.4312 - val_accuracy: 0.7998\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.4342 - val_accuracy: 0.7975\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8020 - val_loss: 0.4299 - val_accuracy: 0.7952\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8018 - val_loss: 0.4298 - val_accuracy: 0.7917\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4394 - val_accuracy: 0.7940\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7968 - val_loss: 0.4399 - val_accuracy: 0.8021\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7953 - val_loss: 0.4435 - val_accuracy: 0.7906\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7962 - val_loss: 0.4391 - val_accuracy: 0.7975\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7998 - val_loss: 0.4473 - val_accuracy: 0.7940\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8024 - val_loss: 0.4390 - val_accuracy: 0.7952\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7970 - val_loss: 0.4402 - val_accuracy: 0.7917\nEpoch 27/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7931 - val_loss: 0.4402 - val_accuracy: 0.7940\nEpoch 28/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8000 - val_loss: 0.4271 - val_accuracy: 0.8044\nEpoch 29/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4348 - val_accuracy: 0.7940\nEpoch 30/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7947 - val_loss: 0.4321 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7839\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.7746 - val_loss: 0.4507 - val_accuracy: 0.7986\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.4424 - val_accuracy: 0.7975\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7890 - val_loss: 0.4379 - val_accuracy: 0.7883\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7875 - val_loss: 0.4458 - val_accuracy: 0.7940\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7839 - val_loss: 0.4527 - val_accuracy: 0.7940\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7884 - val_loss: 0.4480 - val_accuracy: 0.7998\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7903 - val_loss: 0.4406 - val_accuracy: 0.7917\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.4302 - val_accuracy: 0.7837\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7927 - val_loss: 0.4464 - val_accuracy: 0.7963\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7942 - val_loss: 0.4525 - val_accuracy: 0.7917\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7916 - val_loss: 0.4309 - val_accuracy: 0.7963\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7931 - val_loss: 0.4317 - val_accuracy: 0.7940\nEpoch 13/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.4548 - val_accuracy: 0.7572\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7962 - val_loss: 0.4610 - val_accuracy: 0.7745\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7940 - val_loss: 0.4453 - val_accuracy: 0.7906\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7910 - val_loss: 0.4322 - val_accuracy: 0.7917\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7936 - val_loss: 0.4382 - val_accuracy: 0.7975\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7903 - val_loss: 0.4293 - val_accuracy: 0.7986\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7957 - val_loss: 0.4314 - val_accuracy: 0.7952\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7979 - val_loss: 0.4318 - val_accuracy: 0.7917\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7940 - val_loss: 0.4265 - val_accuracy: 0.7975\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4367 - val_accuracy: 0.7894\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7931 - val_loss: 0.4266 - val_accuracy: 0.7883\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7968 - val_loss: 0.4361 - val_accuracy: 0.7860\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4414 - val_accuracy: 0.7917\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7957 - val_loss: 0.4339 - val_accuracy: 0.7860\nEpoch 27/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7955 - val_loss: 0.4298 - val_accuracy: 0.7963\nEpoch 28/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7962 - val_loss: 0.4339 - val_accuracy: 0.7975\nEpoch 29/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7962 - val_loss: 0.4367 - val_accuracy: 0.7917\nEpoch 30/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8020 - val_loss: 0.4299 - val_accuracy: 0.7952\n73/73 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7903\nEpoch 1/30\n145/145 [==============================] - 2s 10ms/step - loss: 0.9661 - accuracy: 0.6967 - val_loss: 0.7901 - val_accuracy: 0.7112\nEpoch 2/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.6175 - accuracy: 0.7321 - val_loss: 0.4977 - val_accuracy: 0.7814\nEpoch 3/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.5143 - accuracy: 0.7601 - val_loss: 0.4756 - val_accuracy: 0.7906\nEpoch 4/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4878 - accuracy: 0.7636 - val_loss: 0.4925 - val_accuracy: 0.7503\nEpoch 5/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4591 - accuracy: 0.7832 - val_loss: 0.4615 - val_accuracy: 0.7848\nEpoch 6/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.4378 - val_accuracy: 0.7756\nEpoch 7/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4509 - accuracy: 0.7875 - val_loss: 0.4515 - val_accuracy: 0.7802\nEpoch 8/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.4470 - val_accuracy: 0.7917\nEpoch 9/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.7923 - val_loss: 0.4427 - val_accuracy: 0.7883\nEpoch 10/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4482 - accuracy: 0.7914 - val_loss: 0.4252 - val_accuracy: 0.7940\nEpoch 11/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4413 - accuracy: 0.7873 - val_loss: 0.4350 - val_accuracy: 0.7687\nEpoch 12/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4400 - accuracy: 0.7996 - val_loss: 0.4278 - val_accuracy: 0.7894\nEpoch 13/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4394 - accuracy: 0.7931 - val_loss: 0.4313 - val_accuracy: 0.7825\nEpoch 14/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4420 - accuracy: 0.7903 - val_loss: 0.4343 - val_accuracy: 0.7952\nEpoch 15/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4363 - accuracy: 0.7906 - val_loss: 0.4377 - val_accuracy: 0.7860\nEpoch 16/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.4390 - val_accuracy: 0.7917\nEpoch 17/30\n145/145 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7912 - val_loss: 0.4465 - val_accuracy: 0.7745\nEpoch 18/30\n145/145 [==============================] - 1s 9ms/step - loss: 0.4329 - accuracy: 0.7931 - val_loss: 0.4473 - val_accuracy: 0.7883\nEpoch 19/30\n145/145 [==============================] - 1s 9ms/step - loss: 0.4340 - accuracy: 0.7929 - val_loss: 0.4679 - val_accuracy: 0.7837\nEpoch 20/30\n145/145 [==============================] - 1s 9ms/step - loss: 0.4312 - accuracy: 0.7972 - val_loss: 0.4439 - val_accuracy: 0.7860\n73/73 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7843\nEpoch 1/30\n145/145 [==============================] - 2s 9ms/step - loss: 0.9079 - accuracy: 0.7133 - val_loss: 0.6551 - val_accuracy: 0.7583\nEpoch 2/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.6076 - accuracy: 0.7286 - val_loss: 0.5577 - val_accuracy: 0.7791\nEpoch 3/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.5128 - accuracy: 0.7608 - val_loss: 0.4699 - val_accuracy: 0.7779\nEpoch 4/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4749 - accuracy: 0.7686 - val_loss: 0.5183 - val_accuracy: 0.6928\nEpoch 5/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4539 - accuracy: 0.7800 - val_loss: 0.4495 - val_accuracy: 0.7917\nEpoch 6/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4474 - accuracy: 0.7821 - val_loss: 0.4775 - val_accuracy: 0.7963\nEpoch 7/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4420 - accuracy: 0.7897 - val_loss: 0.4467 - val_accuracy: 0.7848\nEpoch 8/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.7910 - val_loss: 0.4320 - val_accuracy: 0.7952\nEpoch 9/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4318 - accuracy: 0.7880 - val_loss: 0.4352 - val_accuracy: 0.7998\nEpoch 10/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4309 - accuracy: 0.7966 - val_loss: 0.4604 - val_accuracy: 0.7871\nEpoch 11/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4293 - accuracy: 0.7981 - val_loss: 0.4877 - val_accuracy: 0.7883\nEpoch 12/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4280 - accuracy: 0.7966 - val_loss: 0.4391 - val_accuracy: 0.7848\nEpoch 13/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4265 - accuracy: 0.7975 - val_loss: 0.4512 - val_accuracy: 0.7963\nEpoch 14/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4247 - accuracy: 0.7979 - val_loss: 0.4423 - val_accuracy: 0.7687\nEpoch 15/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4234 - accuracy: 0.7964 - val_loss: 0.4485 - val_accuracy: 0.7906\nEpoch 16/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.7940 - val_loss: 0.4397 - val_accuracy: 0.7871\nEpoch 17/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4217 - accuracy: 0.7955 - val_loss: 0.4597 - val_accuracy: 0.7986\nEpoch 18/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4205 - accuracy: 0.7994 - val_loss: 0.4555 - val_accuracy: 0.7894\n73/73 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7826\nEpoch 1/30\n145/145 [==============================] - 2s 9ms/step - loss: 0.9491 - accuracy: 0.7125 - val_loss: 0.5497 - val_accuracy: 0.7491\nEpoch 2/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.6028 - accuracy: 0.7409 - val_loss: 0.5584 - val_accuracy: 0.7837\nEpoch 3/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.5125 - accuracy: 0.7580 - val_loss: 0.4539 - val_accuracy: 0.7837\nEpoch 4/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4761 - accuracy: 0.7735 - val_loss: 0.4333 - val_accuracy: 0.7894\nEpoch 5/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4547 - accuracy: 0.7811 - val_loss: 0.4356 - val_accuracy: 0.7894\nEpoch 6/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.4535 - val_accuracy: 0.7779\nEpoch 7/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4384 - accuracy: 0.7910 - val_loss: 0.4610 - val_accuracy: 0.7860\nEpoch 8/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.7955 - val_loss: 0.4300 - val_accuracy: 0.7929\nEpoch 9/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4366 - accuracy: 0.7942 - val_loss: 0.4311 - val_accuracy: 0.7940\nEpoch 10/30\n145/145 [==============================] - 1s 9ms/step - loss: 0.4283 - accuracy: 0.8009 - val_loss: 0.4408 - val_accuracy: 0.7802\nEpoch 11/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4273 - accuracy: 0.8011 - val_loss: 0.4522 - val_accuracy: 0.7860\nEpoch 12/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4252 - accuracy: 0.7929 - val_loss: 0.4511 - val_accuracy: 0.7814\nEpoch 13/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4226 - accuracy: 0.8005 - val_loss: 0.4434 - val_accuracy: 0.7745\nEpoch 14/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4226 - accuracy: 0.7947 - val_loss: 0.4492 - val_accuracy: 0.7825\nEpoch 15/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.7998 - val_loss: 0.4350 - val_accuracy: 0.7894\nEpoch 16/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4235 - accuracy: 0.7966 - val_loss: 0.4406 - val_accuracy: 0.7883\nEpoch 17/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4185 - accuracy: 0.8046 - val_loss: 0.4695 - val_accuracy: 0.7814\nEpoch 18/30\n145/145 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.7983 - val_loss: 0.4644 - val_accuracy: 0.7871\n73/73 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7929\nEpoch 1/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.5603 - accuracy: 0.7422 - val_loss: 0.5070 - val_accuracy: 0.7952\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7705 - val_loss: 0.5138 - val_accuracy: 0.7537\nEpoch 3/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7731 - val_loss: 0.4851 - val_accuracy: 0.7526\nEpoch 4/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7752 - val_loss: 0.4644 - val_accuracy: 0.7722\nEpoch 5/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7789 - val_loss: 0.4346 - val_accuracy: 0.7917\nEpoch 6/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7839 - val_loss: 0.4465 - val_accuracy: 0.7802\nEpoch 7/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7815 - val_loss: 0.4569 - val_accuracy: 0.7825\nEpoch 8/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7867 - val_loss: 0.4332 - val_accuracy: 0.7825\nEpoch 9/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7880 - val_loss: 0.4392 - val_accuracy: 0.7825\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7893 - val_loss: 0.4437 - val_accuracy: 0.7802\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4370 - val_accuracy: 0.7871\nEpoch 12/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7888 - val_loss: 0.4486 - val_accuracy: 0.7848\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7977 - val_loss: 0.4577 - val_accuracy: 0.7802\nEpoch 14/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7916 - val_loss: 0.4436 - val_accuracy: 0.7848\nEpoch 15/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7914 - val_loss: 0.4379 - val_accuracy: 0.7906\nEpoch 16/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7890 - val_loss: 0.4245 - val_accuracy: 0.7929\nEpoch 17/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7929 - val_loss: 0.4262 - val_accuracy: 0.7768\nEpoch 18/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7953 - val_loss: 0.4540 - val_accuracy: 0.7871\nEpoch 19/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7972 - val_loss: 0.4400 - val_accuracy: 0.7837\nEpoch 20/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7981 - val_loss: 0.4458 - val_accuracy: 0.7871\nEpoch 21/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7994 - val_loss: 0.4240 - val_accuracy: 0.7883\nEpoch 22/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7970 - val_loss: 0.4207 - val_accuracy: 0.7975\nEpoch 23/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7987 - val_loss: 0.4520 - val_accuracy: 0.7583\nEpoch 24/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8018 - val_loss: 0.4491 - val_accuracy: 0.7871\nEpoch 25/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7966 - val_loss: 0.4325 - val_accuracy: 0.7860\nEpoch 26/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8052 - val_loss: 0.4636 - val_accuracy: 0.7791\nEpoch 27/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8048 - val_loss: 0.4372 - val_accuracy: 0.7871\nEpoch 28/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8041 - val_loss: 0.4340 - val_accuracy: 0.7883\nEpoch 29/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7983 - val_loss: 0.4366 - val_accuracy: 0.7837\nEpoch 30/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.4340 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.7895\nEpoch 1/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.5513 - accuracy: 0.7453 - val_loss: 0.4707 - val_accuracy: 0.7768\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7660 - val_loss: 0.4778 - val_accuracy: 0.7883\nEpoch 3/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7755 - val_loss: 0.4579 - val_accuracy: 0.7825\nEpoch 4/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7811 - val_loss: 0.4653 - val_accuracy: 0.7595\nEpoch 5/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7841 - val_loss: 0.4384 - val_accuracy: 0.7848\nEpoch 6/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7888 - val_loss: 0.4243 - val_accuracy: 0.7929\nEpoch 7/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7918 - val_loss: 0.4459 - val_accuracy: 0.7929\nEpoch 8/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7901 - val_loss: 0.4547 - val_accuracy: 0.7894\nEpoch 9/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7947 - val_loss: 0.4325 - val_accuracy: 0.7848\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7877 - val_loss: 0.4385 - val_accuracy: 0.7871\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7903 - val_loss: 0.4491 - val_accuracy: 0.7860\nEpoch 12/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7949 - val_loss: 0.4618 - val_accuracy: 0.7687\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7929 - val_loss: 0.4342 - val_accuracy: 0.7825\nEpoch 14/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8016 - val_loss: 0.4391 - val_accuracy: 0.7906\nEpoch 15/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7964 - val_loss: 0.4413 - val_accuracy: 0.7883\nEpoch 16/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7985 - val_loss: 0.4541 - val_accuracy: 0.7917\n73/73 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7886\nEpoch 1/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.5407 - accuracy: 0.7545 - val_loss: 0.4613 - val_accuracy: 0.7848\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7686 - val_loss: 0.4498 - val_accuracy: 0.7837\nEpoch 3/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7770 - val_loss: 0.5436 - val_accuracy: 0.7779\nEpoch 4/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7826 - val_loss: 0.5592 - val_accuracy: 0.7307\nEpoch 5/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7798 - val_loss: 0.4435 - val_accuracy: 0.7860\nEpoch 6/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7811 - val_loss: 0.4591 - val_accuracy: 0.7814\nEpoch 7/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4475 - val_accuracy: 0.7837\nEpoch 8/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7849 - val_loss: 0.4489 - val_accuracy: 0.7860\nEpoch 9/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7895 - val_loss: 0.4582 - val_accuracy: 0.7894\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7992 - val_loss: 0.4829 - val_accuracy: 0.7871\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7931 - val_loss: 0.4528 - val_accuracy: 0.7894\nEpoch 12/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7970 - val_loss: 0.4521 - val_accuracy: 0.7929\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7959 - val_loss: 0.4428 - val_accuracy: 0.7837\nEpoch 14/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7983 - val_loss: 0.4420 - val_accuracy: 0.7768\nEpoch 15/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7949 - val_loss: 0.4550 - val_accuracy: 0.7687\nEpoch 16/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.4360 - val_accuracy: 0.7906\nEpoch 17/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8039 - val_loss: 0.4478 - val_accuracy: 0.7675\nEpoch 18/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7981 - val_loss: 0.4594 - val_accuracy: 0.7894\nEpoch 19/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7996 - val_loss: 0.4532 - val_accuracy: 0.7906\nEpoch 20/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8016 - val_loss: 0.4422 - val_accuracy: 0.7814\nEpoch 21/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8022 - val_loss: 0.4530 - val_accuracy: 0.7802\nEpoch 22/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8052 - val_loss: 0.4343 - val_accuracy: 0.7894\nEpoch 23/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.7981 - val_loss: 0.4548 - val_accuracy: 0.7791\nEpoch 24/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8072 - val_loss: 0.4482 - val_accuracy: 0.7814\nEpoch 25/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8037 - val_loss: 0.4638 - val_accuracy: 0.7756\nEpoch 26/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8057 - val_loss: 0.4425 - val_accuracy: 0.7860\nEpoch 27/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8046 - val_loss: 0.4428 - val_accuracy: 0.7883\nEpoch 28/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8072 - val_loss: 0.4516 - val_accuracy: 0.7860\nEpoch 29/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8059 - val_loss: 0.4513 - val_accuracy: 0.7894\nEpoch 30/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8041 - val_loss: 0.4603 - val_accuracy: 0.7860\n73/73 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7890\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7556 - val_loss: 0.4757 - val_accuracy: 0.7825\nEpoch 2/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7694 - val_loss: 0.4700 - val_accuracy: 0.7503\nEpoch 3/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7804 - val_loss: 0.4490 - val_accuracy: 0.7883\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7845 - val_loss: 0.4378 - val_accuracy: 0.7929\nEpoch 5/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7802 - val_loss: 0.4380 - val_accuracy: 0.7894\nEpoch 6/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7875 - val_loss: 0.4418 - val_accuracy: 0.7860\nEpoch 7/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7867 - val_loss: 0.4416 - val_accuracy: 0.7917\nEpoch 8/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7880 - val_loss: 0.4399 - val_accuracy: 0.7940\nEpoch 9/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7888 - val_loss: 0.4399 - val_accuracy: 0.7963\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7901 - val_loss: 0.4788 - val_accuracy: 0.7825\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7925 - val_loss: 0.4481 - val_accuracy: 0.7883\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7921 - val_loss: 0.4343 - val_accuracy: 0.7986\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7944 - val_loss: 0.4530 - val_accuracy: 0.7837\nEpoch 14/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7893 - val_loss: 0.4330 - val_accuracy: 0.7883\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.4403 - val_accuracy: 0.7652\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7959 - val_loss: 0.4361 - val_accuracy: 0.7814\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.7802\nEpoch 18/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7979 - val_loss: 0.4527 - val_accuracy: 0.7860\nEpoch 19/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7998 - val_loss: 0.4300 - val_accuracy: 0.7929\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8059 - val_loss: 0.4300 - val_accuracy: 0.7940\nEpoch 21/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7977 - val_loss: 0.4379 - val_accuracy: 0.7883\nEpoch 22/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7975 - val_loss: 0.4399 - val_accuracy: 0.7722\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8013 - val_loss: 0.4300 - val_accuracy: 0.7917\nEpoch 24/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7977 - val_loss: 0.4522 - val_accuracy: 0.7791\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7966 - val_loss: 0.4362 - val_accuracy: 0.7871\nEpoch 26/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8024 - val_loss: 0.4261 - val_accuracy: 0.7917\nEpoch 27/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8007 - val_loss: 0.4393 - val_accuracy: 0.7791\nEpoch 28/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8026 - val_loss: 0.4376 - val_accuracy: 0.7837\nEpoch 29/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8052 - val_loss: 0.4549 - val_accuracy: 0.7710\nEpoch 30/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7972 - val_loss: 0.4389 - val_accuracy: 0.7894\n73/73 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7951\nEpoch 1/30\n145/145 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7657 - val_loss: 0.4918 - val_accuracy: 0.7514\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7817 - val_loss: 0.4604 - val_accuracy: 0.7940\nEpoch 3/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4539 - val_accuracy: 0.7802\nEpoch 4/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4449 - val_accuracy: 0.7975\nEpoch 5/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7871 - val_loss: 0.4602 - val_accuracy: 0.7906\nEpoch 6/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7921 - val_loss: 0.4331 - val_accuracy: 0.8009\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7912 - val_loss: 0.4441 - val_accuracy: 0.8044\nEpoch 8/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7972 - val_loss: 0.4306 - val_accuracy: 0.7929\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7949 - val_loss: 0.4339 - val_accuracy: 0.7975\nEpoch 10/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7938 - val_loss: 0.4337 - val_accuracy: 0.7837\nEpoch 11/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7964 - val_loss: 0.4380 - val_accuracy: 0.7929\nEpoch 12/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7944 - val_loss: 0.4495 - val_accuracy: 0.7906\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7964 - val_loss: 0.4295 - val_accuracy: 0.7917\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7970 - val_loss: 0.4319 - val_accuracy: 0.7940\nEpoch 15/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7987 - val_loss: 0.4373 - val_accuracy: 0.7871\nEpoch 16/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7947 - val_loss: 0.4271 - val_accuracy: 0.7883\nEpoch 17/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8013 - val_loss: 0.4357 - val_accuracy: 0.8009\nEpoch 18/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8013 - val_loss: 0.4383 - val_accuracy: 0.7906\nEpoch 19/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8026 - val_loss: 0.4357 - val_accuracy: 0.7687\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8039 - val_loss: 0.4324 - val_accuracy: 0.7894\nEpoch 21/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7990 - val_loss: 0.4414 - val_accuracy: 0.7848\nEpoch 22/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8046 - val_loss: 0.4273 - val_accuracy: 0.7940\nEpoch 23/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8024 - val_loss: 0.4338 - val_accuracy: 0.7929\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8048 - val_loss: 0.4408 - val_accuracy: 0.7848\nEpoch 25/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8035 - val_loss: 0.4285 - val_accuracy: 0.7906\nEpoch 26/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8046 - val_loss: 0.4383 - val_accuracy: 0.7871\n73/73 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7834\nEpoch 1/30\n145/145 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7636 - val_loss: 0.5139 - val_accuracy: 0.7537\nEpoch 2/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7783 - val_loss: 0.4611 - val_accuracy: 0.7699\nEpoch 3/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7776 - val_loss: 0.4386 - val_accuracy: 0.7837\nEpoch 4/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7875 - val_loss: 0.4697 - val_accuracy: 0.7710\nEpoch 5/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7940 - val_loss: 0.4785 - val_accuracy: 0.7664\nEpoch 6/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7953 - val_loss: 0.4539 - val_accuracy: 0.7894\nEpoch 7/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7964 - val_loss: 0.4600 - val_accuracy: 0.7837\nEpoch 8/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7921 - val_loss: 0.4465 - val_accuracy: 0.7779\nEpoch 9/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7955 - val_loss: 0.4384 - val_accuracy: 0.7975\nEpoch 10/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7918 - val_loss: 0.4551 - val_accuracy: 0.7825\nEpoch 11/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4460 - val_accuracy: 0.7814\nEpoch 12/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7964 - val_loss: 0.4469 - val_accuracy: 0.7675\nEpoch 13/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7949 - val_loss: 0.4414 - val_accuracy: 0.7871\nEpoch 14/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8031 - val_loss: 0.4499 - val_accuracy: 0.7871\nEpoch 15/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7970 - val_loss: 0.4471 - val_accuracy: 0.7883\nEpoch 16/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.4373 - val_accuracy: 0.7860\nEpoch 17/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7992 - val_loss: 0.4488 - val_accuracy: 0.7848\nEpoch 18/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8018 - val_loss: 0.4481 - val_accuracy: 0.7848\nEpoch 19/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8026 - val_loss: 0.4375 - val_accuracy: 0.7699\nEpoch 20/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8031 - val_loss: 0.4520 - val_accuracy: 0.7664\nEpoch 21/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8009 - val_loss: 0.4501 - val_accuracy: 0.7860\nEpoch 22/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8018 - val_loss: 0.4455 - val_accuracy: 0.7825\nEpoch 23/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7985 - val_loss: 0.4574 - val_accuracy: 0.7837\nEpoch 24/30\n145/145 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8035 - val_loss: 0.4425 - val_accuracy: 0.7779\nEpoch 25/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8041 - val_loss: 0.4579 - val_accuracy: 0.7825\nEpoch 26/30\n145/145 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8061 - val_loss: 0.4466 - val_accuracy: 0.7802\n73/73 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7774\nEpoch 1/30\n218/218 [==============================] - 2s 7ms/step - loss: 0.6944 - accuracy: 0.7295 - val_loss: 0.9470 - val_accuracy: 0.6605\nEpoch 2/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.5027 - accuracy: 0.7640 - val_loss: 0.4848 - val_accuracy: 0.7756\nEpoch 3/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4614 - accuracy: 0.7793 - val_loss: 0.5392 - val_accuracy: 0.6962\nEpoch 4/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.7867 - val_loss: 0.4561 - val_accuracy: 0.7745\nEpoch 5/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4411 - accuracy: 0.7909 - val_loss: 0.4622 - val_accuracy: 0.7756\nEpoch 6/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.7902 - val_loss: 0.4267 - val_accuracy: 0.7975\nEpoch 7/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.7957 - val_loss: 0.4583 - val_accuracy: 0.7883\nEpoch 8/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4322 - accuracy: 0.7988 - val_loss: 0.4576 - val_accuracy: 0.7952\nEpoch 9/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7923 - val_loss: 0.4634 - val_accuracy: 0.7814\nEpoch 10/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4300 - accuracy: 0.7936 - val_loss: 0.4529 - val_accuracy: 0.7468\nEpoch 11/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.7931 - val_loss: 0.4415 - val_accuracy: 0.7814\nEpoch 12/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4269 - accuracy: 0.8005 - val_loss: 0.4354 - val_accuracy: 0.7883\nEpoch 13/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.8011 - val_loss: 0.4701 - val_accuracy: 0.7675\nEpoch 14/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.7931 - val_loss: 0.4333 - val_accuracy: 0.7779\nEpoch 15/30\n218/218 [==============================] - 1s 7ms/step - loss: 0.4251 - accuracy: 0.8007 - val_loss: 0.4297 - val_accuracy: 0.7929\nEpoch 16/30\n218/218 [==============================] - 1s 6ms/step - loss: 0.4235 - accuracy: 0.7957 - val_loss: 0.4347 - val_accuracy: 0.7791\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7ad692ffa170>,\n                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ad692ff9b70>,\n                                        'n_hidden': [1, 2, 3, 4, 5],\n                                        'n_neurons': [50, 100, 200, 300, 400,\n                                                      500]})","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7ad692ffa170&gt;,\n                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ad692ff9b70&gt;,\n                                        &#x27;n_hidden&#x27;: [1, 2, 3, 4, 5],\n                                        &#x27;n_neurons&#x27;: [50, 100, 200, 300, 400,\n                                                      500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7ad692ffa170&gt;,\n                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ad692ff9b70&gt;,\n                                        &#x27;n_hidden&#x27;: [1, 2, 3, 4, 5],\n                                        &#x27;n_neurons&#x27;: [50, 100, 200, 300, 400,\n                                                      500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7ad692ffa170&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7ad692ffa170&gt;</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"rnd_search_cv.best_params_\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:22:31.025726Z","iopub.execute_input":"2023-08-12T10:22:31.027725Z","iopub.status.idle":"2023-08-12T10:22:31.033933Z","shell.execute_reply.started":"2023-08-12T10:22:31.027684Z","shell.execute_reply":"2023-08-12T10:22:31.032861Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.009745023607424299, 'n_hidden': 3, 'n_neurons': 500}"},"metadata":{}}]},{"cell_type":"code","source":"rnd_search_cv.best_score_\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:22:31.035534Z","iopub.execute_input":"2023-08-12T10:22:31.035825Z","iopub.status.idle":"2023-08-12T10:22:31.048831Z","shell.execute_reply.started":"2023-08-12T10:22:31.035801Z","shell.execute_reply":"2023-08-12T10:22:31.047901Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"0.7922059297561646"},"metadata":{}}]},{"cell_type":"code","source":"from functools import partial \n\nDense = partial(keras.layers.Dense, \n               activation = 'selu',\n               kernel_initializer='lecun_normal')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:22:31.050244Z","iopub.execute_input":"2023-08-12T10:22:31.051410Z","iopub.status.idle":"2023-08-12T10:22:31.059844Z","shell.execute_reply.started":"2023-08-12T10:22:31.051356Z","shell.execute_reply":"2023-08-12T10:22:31.058302Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.InputLayer(input_shape=20),\n    Dense(500),\n    Dense(500),\n    keras.layers.AlphaDropout(rate=0.2),\n    Dense(500),\n    keras.layers.AlphaDropout(rate=0.2),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:23:58.156226Z","iopub.execute_input":"2023-08-12T10:23:58.156571Z","iopub.status.idle":"2023-08-12T10:23:58.216297Z","shell.execute_reply.started":"2023-08-12T10:23:58.156544Z","shell.execute_reply":"2023-08-12T10:23:58.215326Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:01.297081Z","iopub.execute_input":"2023-08-12T10:24:01.297471Z","iopub.status.idle":"2023-08-12T10:24:01.303831Z","shell.execute_reply.started":"2023-08-12T10:24:01.297442Z","shell.execute_reply":"2023-08-12T10:24:01.302439Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:03.144011Z","iopub.execute_input":"2023-08-12T10:24:03.144950Z","iopub.status.idle":"2023-08-12T10:24:03.167626Z","shell.execute_reply.started":"2023-08-12T10:24:03.144887Z","shell.execute_reply":"2023-08-12T10:24:03.166065Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Model: \"sequential_34\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_125 (Dense)           (None, 500)               10500     \n                                                                 \n dense_126 (Dense)           (None, 500)               250500    \n                                                                 \n alpha_dropout_6 (AlphaDropo  (None, 500)              0         \n ut)                                                             \n                                                                 \n dense_127 (Dense)           (None, 500)               250500    \n                                                                 \n alpha_dropout_7 (AlphaDropo  (None, 500)              0         \n ut)                                                             \n                                                                 \n dense_128 (Dense)           (None, 1)                 501       \n                                                                 \n=================================================================\nTotal params: 512,001\nTrainable params: 512,001\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\",\n optimizer='RMSprop',\n metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:05.765955Z","iopub.execute_input":"2023-08-12T10:24:05.766305Z","iopub.status.idle":"2023-08-12T10:24:05.776958Z","shell.execute_reply.started":"2023-08-12T10:24:05.766279Z","shell.execute_reply":"2023-08-12T10:24:05.775892Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":" history = model.fit(X_train_prepared, y_train, epochs=50, validation_data=(X_val_prepared, y_val), callbacks=[lr_scheduler,early_stopping,checkpoint_cb])","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:08.334365Z","iopub.execute_input":"2023-08-12T10:24:08.334708Z","iopub.status.idle":"2023-08-12T10:24:39.264081Z","shell.execute_reply.started":"2023-08-12T10:24:08.334678Z","shell.execute_reply":"2023-08-12T10:24:39.262195Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Epoch 1/50\n218/218 [==============================] - 2s 7ms/step - loss: 0.6094 - accuracy: 0.7384 - val_loss: 0.4969 - val_accuracy: 0.7802 - lr: 0.0010\nEpoch 2/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.7601 - val_loss: 0.7780 - val_accuracy: 0.6835 - lr: 0.0010\nEpoch 3/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4589 - accuracy: 0.7793 - val_loss: 0.5746 - val_accuracy: 0.7779 - lr: 0.0010\nEpoch 4/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4498 - accuracy: 0.7837 - val_loss: 0.4922 - val_accuracy: 0.7860 - lr: 0.0010\nEpoch 5/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.7794 - val_loss: 0.5976 - val_accuracy: 0.7664 - lr: 0.0010\nEpoch 6/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4442 - accuracy: 0.7880 - val_loss: 0.5520 - val_accuracy: 0.7445 - lr: 0.0010\nEpoch 7/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.7869 - val_loss: 0.4987 - val_accuracy: 0.7894 - lr: 0.0010\nEpoch 8/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.7908 - val_loss: 0.5042 - val_accuracy: 0.7837 - lr: 5.0000e-04\nEpoch 9/50\n218/218 [==============================] - 2s 7ms/step - loss: 0.4249 - accuracy: 0.7962 - val_loss: 0.5034 - val_accuracy: 0.7917 - lr: 5.0000e-04\nEpoch 10/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4268 - accuracy: 0.7962 - val_loss: 0.5579 - val_accuracy: 0.7883 - lr: 5.0000e-04\nEpoch 11/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.8016 - val_loss: 0.4708 - val_accuracy: 0.7952 - lr: 2.5000e-04\nEpoch 12/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4167 - accuracy: 0.7982 - val_loss: 0.5130 - val_accuracy: 0.7814 - lr: 2.5000e-04\nEpoch 13/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5357 - val_accuracy: 0.7940 - lr: 2.5000e-04\nEpoch 14/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7906 - lr: 2.5000e-04\nEpoch 15/50\n218/218 [==============================] - 2s 7ms/step - loss: 0.4136 - accuracy: 0.8023 - val_loss: 0.5057 - val_accuracy: 0.7940 - lr: 1.2500e-04\nEpoch 16/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4143 - accuracy: 0.8020 - val_loss: 0.5240 - val_accuracy: 0.7860 - lr: 1.2500e-04\nEpoch 17/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4136 - accuracy: 0.8044 - val_loss: 0.5123 - val_accuracy: 0.7952 - lr: 1.2500e-04\nEpoch 18/50\n218/218 [==============================] - 1s 7ms/step - loss: 0.4095 - accuracy: 0.8020 - val_loss: 0.5072 - val_accuracy: 0.7917 - lr: 6.2500e-05\nEpoch 19/50\n218/218 [==============================] - 2s 7ms/step - loss: 0.4113 - accuracy: 0.8020 - val_loss: 0.5047 - val_accuracy: 0.7906 - lr: 6.2500e-05\nEpoch 20/50\n218/218 [==============================] - 2s 7ms/step - loss: 0.4107 - accuracy: 0.8023 - val_loss: 0.4980 - val_accuracy: 0.7963 - lr: 6.2500e-05\nEpoch 21/50\n218/218 [==============================] - 1s 6ms/step - loss: 0.4093 - accuracy: 0.8057 - val_loss: 0.5100 - val_accuracy: 0.7952 - lr: 3.1250e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test_prepared = full_pipeline.transform(test_full)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:46.526080Z","iopub.execute_input":"2023-08-12T10:24:46.526455Z","iopub.status.idle":"2023-08-12T10:24:46.543750Z","shell.execute_reply.started":"2023-08-12T10:24:46.526429Z","shell.execute_reply":"2023-08-12T10:24:46.542800Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"y_test = model.predict(X_test_prepared)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:48.528633Z","iopub.execute_input":"2023-08-12T10:24:48.529006Z","iopub.status.idle":"2023-08-12T10:24:48.976358Z","shell.execute_reply.started":"2023-08-12T10:24:48.528976Z","shell.execute_reply":"2023-08-12T10:24:48.975040Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"134/134 [==============================] - 0s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"Transported = []\nfor proba_of_transportation in y_test:\n    if proba_of_transportation > 0.5:\n        Transported.append(True)\n    else:\n        Transported.append(False)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:50.781969Z","iopub.execute_input":"2023-08-12T10:24:50.782370Z","iopub.status.idle":"2023-08-12T10:24:50.794966Z","shell.execute_reply.started":"2023-08-12T10:24:50.782340Z","shell.execute_reply":"2023-08-12T10:24:50.793804Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_full.PassengerId, 'Transported': Transported})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:24:53.234272Z","iopub.execute_input":"2023-08-12T10:24:53.234610Z","iopub.status.idle":"2023-08-12T10:24:53.247124Z","shell.execute_reply.started":"2023-08-12T10:24:53.234584Z","shell.execute_reply":"2023-08-12T10:24:53.246123Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"Your submission was successfully saved!\n","output_type":"stream"}]}]}
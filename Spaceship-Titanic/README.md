**The Feature Engineering and Data Cleaning parts of this Notebook are highly inspired and influenced by Kaggle Expert MLCV, credit to him/her for such in-depth analysis of the given dataset. It has really allowed me to broaden my views as Data Scientist and discover techniques I have never given much thought to**
The highest score I was able to achieve in this competition was 0.79448 with a placing of 1043 of 2286 teams. In this project, I focused on practicing my Deep Neural Network modeling skills using TensorFlow's high-level Keras API. While experimenting with many different combinations of activation functions, kernel initializers, and optimizers, including but not limited to activation = ['elu', 'relu', 'selu', 'LeakyReLU'], kernel_initializer = ['lecun_normal', 'he_normal'] and optimizer = ['SGD', 'Adagrad', 'RMSprop', 'Adam', 'Nadam', 'AdaMax'] I found the combination of selu, lecun_nomral and RMSprop to work best with appropriate callbacks. Hence, I decided to focus on this combination of hyperparameters and just played around with the number of layers and neurons with different regularization techniques.

